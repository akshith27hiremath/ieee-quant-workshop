{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Cross-Validation & Data Splits\n",
    "\n",
    "**Goal:** Understand and visualize how we split our data for training, validation, and testing.\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "**Time-series data is special!** We cannot use random splits like in standard ML.\n",
    "\n",
    "### The Problem with Random Splits\n",
    "- Agent could see \"future\" data during training\n",
    "- Results would be unrealistically good\n",
    "- Model wouldn't work in real trading\n",
    "\n",
    "### Our Solution: Time-Based Splits\n",
    "- **Train:** Historical data (agent learns here)\n",
    "- **Validation:** Recent past (tune hyperparameters)\n",
    "- **Test:** Most recent data (final evaluation, never seen during training)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Prepared Data\n",
    "\n",
    "Load the featured data from Notebook 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = Path('demo_data/featured_data.parquet')\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(\"‚ùå Error: Data file not found!\")\n",
    "    print(\"   Please run notebook 01_data_collection.ipynb first\")\n",
    "else:\n",
    "    data = pd.read_parquet(data_path)\n",
    "    print(f\"‚úì Loaded data: {len(data)} rows\")\n",
    "    print(f\"  Date range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "    print(f\"  Columns: {len(data.columns)}\")\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Split Boundaries\n",
    "\n",
    "We'll use a simple time-based split:\n",
    "\n",
    "```\n",
    "2000 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2019 ‚îÄ‚îÄ‚îÄ‚îÄ 2021 ‚îÄ‚îÄ‚îÄ‚îÄ 2024\n",
    "       TRAIN (85%)              VAL(15%) TEST(Hold-out)\n",
    "```\n",
    "\n",
    "### Why These Dates?\n",
    "- **Train:** 2000-2018 (longest period for learning)\n",
    "- **Validation:** 2019-2020 (tune and select best model)\n",
    "- **Test:** 2021-2024 (final evaluation on unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split dates\n",
    "test_start_date = pd.Timestamp('2021-01-01')\n",
    "\n",
    "# Split data\n",
    "train_val_data = data[data.index < test_start_date].copy()\n",
    "test_data = data[data.index >= test_start_date].copy()\n",
    "\n",
    "# Further split train_val into train and validation (85/15 split)\n",
    "train_size = int(len(train_val_data) * 0.85)\n",
    "train_data = train_val_data.iloc[:train_size]\n",
    "val_data = train_val_data.iloc[train_size:]\n",
    "\n",
    "print(\"Data Split Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTRAIN SET:\")\n",
    "print(f\"  Dates: {train_data.index[0].date()} to {train_data.index[-1].date()}\")\n",
    "print(f\"  Rows: {len(train_data):,}\")\n",
    "print(f\"  Percentage: {len(train_data)/len(data)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nVALIDATION SET:\")\n",
    "print(f\"  Dates: {val_data.index[0].date()} to {val_data.index[-1].date()}\")\n",
    "print(f\"  Rows: {len(val_data):,}\")\n",
    "print(f\"  Percentage: {len(val_data)/len(data)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nTEST SET (HOLD-OUT):\")\n",
    "print(f\"  Dates: {test_data.index[0].date()} to {test_data.index[-1].date()}\")\n",
    "print(f\"  Rows: {len(test_data):,}\")\n",
    "print(f\"  Percentage: {len(test_data)/len(data)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nTOTAL: {len(data):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the Split\n",
    "\n",
    "Let's see exactly where our splits occur in the price history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive split visualization\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "# 1. Full timeline with colored regions\n",
    "ax1 = axes[0]\n",
    "ax1.plot(data.index, data['close'], linewidth=1, color='gray', alpha=0.5)\n",
    "\n",
    "# Color the regions\n",
    "ax1.fill_between(train_data.index, train_data['close'].min(), train_data['close'].max(),\n",
    "                  alpha=0.2, color='blue', label='Train')\n",
    "ax1.fill_between(val_data.index, val_data['close'].min(), val_data['close'].max(),\n",
    "                  alpha=0.2, color='orange', label='Validation')\n",
    "ax1.fill_between(test_data.index, test_data['close'].min(), test_data['close'].max(),\n",
    "                  alpha=0.2, color='green', label='Test')\n",
    "\n",
    "ax1.axvline(x=train_data.index[-1], color='red', linestyle='--', linewidth=2, label='Split: Train/Val')\n",
    "ax1.axvline(x=test_data.index[0], color='purple', linestyle='--', linewidth=2, label='Split: Val/Test')\n",
    "\n",
    "ax1.set_title('Data Split Timeline - Full View', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('SPY Price ($)', fontsize=11)\n",
    "ax1.legend(loc='upper left', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Individual periods side by side\n",
    "ax2 = axes[1]\n",
    "ax2.plot(train_data.index, train_data['close'], label='Train', linewidth=1.5, color='blue', alpha=0.7)\n",
    "ax2.plot(val_data.index, val_data['close'], label='Validation', linewidth=1.5, color='orange', alpha=0.7)\n",
    "ax2.plot(test_data.index, test_data['close'], label='Test', linewidth=1.5, color='green', alpha=0.7)\n",
    "ax2.set_title('Each Data Split Period', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('SPY Price ($)', fontsize=11)\n",
    "ax2.legend(loc='upper left', fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Returns distribution across splits\n",
    "ax3 = axes[2]\n",
    "ax3.hist(train_data['return_1d'].dropna(), bins=100, alpha=0.5, label='Train', color='blue', density=True)\n",
    "ax3.hist(val_data['return_1d'].dropna(), bins=100, alpha=0.5, label='Validation', color='orange', density=True)\n",
    "ax3.hist(test_data['return_1d'].dropna(), bins=100, alpha=0.5, label='Test', color='green', density=True)\n",
    "ax3.set_title('Daily Returns Distribution Across Splits', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Daily Return', fontsize=11)\n",
    "ax3.set_ylabel('Density', fontsize=11)\n",
    "ax3.legend(loc='upper right', fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('demo_outputs/data_splits.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Saved visualization: demo_outputs/data_splits.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare Statistics Across Splits\n",
    "\n",
    "Let's verify that our splits are reasonable by comparing basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each split\n",
    "def get_split_stats(df, name):\n",
    "    returns = df['return_1d'].dropna()\n",
    "    return {\n",
    "        'Split': name,\n",
    "        'Mean Return': returns.mean(),\n",
    "        'Std Return': returns.std(),\n",
    "        'Sharpe': (returns.mean() / returns.std()) * np.sqrt(252),\n",
    "        'Min Return': returns.min(),\n",
    "        'Max Return': returns.max(),\n",
    "        'Price Start': df['close'].iloc[0],\n",
    "        'Price End': df['close'].iloc[-1],\n",
    "        'Total Return': (df['close'].iloc[-1] / df['close'].iloc[0]) - 1\n",
    "    }\n",
    "\n",
    "stats_df = pd.DataFrame([\n",
    "    get_split_stats(train_data, 'Train'),\n",
    "    get_split_stats(val_data, 'Validation'),\n",
    "    get_split_stats(test_data, 'Test')\n",
    "])\n",
    "\n",
    "print(\"\\nStatistics Comparison Across Splits\")\n",
    "print(\"=\" * 100)\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "# Check for significant differences\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Observations:\")\n",
    "print(f\"  ‚Ä¢ Train period total return: {stats_df.loc[0, 'Total Return']:.1%}\")\n",
    "print(f\"  ‚Ä¢ Validation period total return: {stats_df.loc[1, 'Total Return']:.1%}\")\n",
    "print(f\"  ‚Ä¢ Test period total return: {stats_df.loc[2, 'Total Return']:.1%}\")\n",
    "print(f\"  ‚Ä¢ Train volatility: {stats_df.loc[0, 'Std Return']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Test volatility: {stats_df.loc[2, 'Std Return']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Feature Distribution Check\n",
    "\n",
    "Verify that feature distributions are similar across splits (important for generalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features to compare\n",
    "key_features = ['return_1d', 'rsi', 'macd', 'volume_ratio', 'bb_percent']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot distributions\n",
    "    train_data[feature].dropna().hist(bins=50, alpha=0.5, label='Train', \n",
    "                                       color='blue', density=True, ax=ax)\n",
    "    val_data[feature].dropna().hist(bins=50, alpha=0.5, label='Val', \n",
    "                                     color='orange', density=True, ax=ax)\n",
    "    test_data[feature].dropna().hist(bins=50, alpha=0.5, label='Test', \n",
    "                                      color='green', density=True, ax=ax)\n",
    "    \n",
    "    ax.set_title(f'{feature}', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.suptitle('Feature Distributions Across Splits', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('demo_outputs/feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Saved visualization: demo_outputs/feature_distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Verify No Data Leakage\n",
    "\n",
    "Critical check: Ensure validation and test sets come AFTER training set in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal ordering check\n",
    "print(\"Data Leakage Check\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_end = train_data.index[-1]\n",
    "val_start = val_data.index[0]\n",
    "val_end = val_data.index[-1]\n",
    "test_start = test_data.index[0]\n",
    "\n",
    "print(f\"\\nTemporal Order:\")\n",
    "print(f\"  Train ends:       {train_end.date()}\")\n",
    "print(f\"  Validation starts: {val_start.date()}\")\n",
    "print(f\"  Gap:              {(val_start - train_end).days} days\")\n",
    "print(f\"  \")\n",
    "print(f\"  Validation ends:  {val_end.date()}\")\n",
    "print(f\"  Test starts:      {test_start.date()}\")\n",
    "print(f\"  Gap:              {(test_start - val_end).days} days\")\n",
    "\n",
    "# Verify no overlap\n",
    "if train_end < val_start and val_end < test_start:\n",
    "    print(\"\\n‚úì PASS: No temporal overlap detected\")\n",
    "    print(\"  ‚Ä¢ Train period is before validation\")\n",
    "    print(\"  ‚Ä¢ Validation period is before test\")\n",
    "    print(\"  ‚Ä¢ No data leakage possible\")\n",
    "else:\n",
    "    print(\"\\n‚ùå FAIL: Temporal overlap detected!\")\n",
    "    print(\"  This would cause data leakage.\")\n",
    "\n",
    "# Check for duplicate indices\n",
    "train_indices = set(train_data.index)\n",
    "val_indices = set(val_data.index)\n",
    "test_indices = set(test_data.index)\n",
    "\n",
    "train_val_overlap = train_indices.intersection(val_indices)\n",
    "val_test_overlap = val_indices.intersection(test_indices)\n",
    "train_test_overlap = train_indices.intersection(test_indices)\n",
    "\n",
    "if not train_val_overlap and not val_test_overlap and not train_test_overlap:\n",
    "    print(\"\\n‚úì PASS: No index overlap between splits\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå FAIL: Index overlap found!\")\n",
    "    if train_val_overlap:\n",
    "        print(f\"  Train-Val overlap: {len(train_val_overlap)} rows\")\n",
    "    if val_test_overlap:\n",
    "        print(f\"  Val-Test overlap: {len(val_test_overlap)} rows\")\n",
    "    if train_test_overlap:\n",
    "        print(f\"  Train-Test overlap: {len(train_test_overlap)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: What the Agent Will See\n",
    "\n",
    "Let's show exactly what data the agent sees at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Agent's View of Data\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìò TRAINING PHASE:\")\n",
    "print(\"  The agent will:\")\n",
    "print(f\"    ‚Ä¢ See {len(train_data):,} days of market data\")\n",
    "print(f\"    ‚Ä¢ Learn from {train_data.index[0].date()} to {train_data.index[-1].date()}\")\n",
    "print(f\"    ‚Ä¢ Take actions and receive rewards based on this period\")\n",
    "print(f\"    ‚Ä¢ Update its neural network weights to maximize rewards\")\n",
    "\n",
    "print(\"\\nüìô VALIDATION PHASE:\")\n",
    "print(\"  During training, the agent will:\")\n",
    "print(f\"    ‚Ä¢ Periodically evaluate on {len(val_data):,} days ({val_data.index[0].date()} to {val_data.index[-1].date()})\")\n",
    "print(f\"    ‚Ä¢ NOT update weights based on validation performance\")\n",
    "print(f\"    ‚Ä¢ Use validation to select the best model checkpoint\")\n",
    "print(f\"    ‚Ä¢ Trigger early stopping if performance plateaus\")\n",
    "\n",
    "print(\"\\nüìó TEST PHASE:\")\n",
    "print(\"  After training is complete, the agent will:\")\n",
    "print(f\"    ‚Ä¢ Run on {len(test_data):,} days ({test_data.index[0].date()} to {test_data.index[-1].date()})\")\n",
    "print(f\"    ‚Ä¢ See this data for the FIRST TIME (never trained on it)\")\n",
    "print(f\"    ‚Ä¢ Final performance here shows true generalization\")\n",
    "print(f\"    ‚Ä¢ This is the 'real-world' performance estimate\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Key Point: The agent NEVER sees test data during training!\")\n",
    "print(\"This ensures our evaluation is realistic and unbiased.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Split Information\n",
    "\n",
    "Save the split configuration for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save split indices for later use\n",
    "split_info = {\n",
    "    'train_start': str(train_data.index[0]),\n",
    "    'train_end': str(train_data.index[-1]),\n",
    "    'train_size': len(train_data),\n",
    "    'val_start': str(val_data.index[0]),\n",
    "    'val_end': str(val_data.index[-1]),\n",
    "    'val_size': len(val_data),\n",
    "    'test_start': str(test_data.index[0]),\n",
    "    'test_end': str(test_data.index[-1]),\n",
    "    'test_size': len(test_data),\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('demo_data/split_info.json', 'w') as f:\n",
    "    json.dump(split_info, f, indent=2)\n",
    "\n",
    "print(\"‚úì Split information saved to: demo_data/split_info.json\")\n",
    "print(\"\\nSplit Info:\")\n",
    "print(json.dumps(split_info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "‚úÖ **Time-series splits are different** from random splits  \n",
    "‚úÖ **Training set** (2000-2018): Agent learns here  \n",
    "‚úÖ **Validation set** (2019-2020): Model selection and early stopping  \n",
    "‚úÖ **Test set** (2021-2024): Final evaluation on unseen data  \n",
    "‚úÖ **No data leakage**: Splits are temporally ordered  \n",
    "‚úÖ **Feature distributions** are reasonably similar across splits  \n",
    "\n",
    "### Why This Split Strategy Works\n",
    "\n",
    "1. **Temporal ordering preserved** ‚Üí Realistic simulation\n",
    "2. **Sufficient training data** ‚Üí Agent can learn patterns\n",
    "3. **Validation for tuning** ‚Üí Prevent overfitting\n",
    "4. **Hold-out test set** ‚Üí Unbiased performance estimate\n",
    "\n",
    "### Common Mistakes We Avoided\n",
    "\n",
    "‚ùå Random splitting time-series data  \n",
    "‚ùå Using test data for hyperparameter tuning  \n",
    "‚ùå Training on future data  \n",
    "‚ùå Not checking for temporal overlap  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**‚Üí Notebook 03:** Agent Training  \n",
    "Now we'll train our DQN agent on the training set and watch it learn in real-time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlquant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
